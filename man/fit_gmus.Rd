% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit_gmus.R
\name{fit_gmus}
\alias{fit_gmus}
\title{Generalized Matrix Uncertainty Selector}
\usage{
fit_gmus(W, y, lambda = NULL, delta = NULL, family = c("gaussian",
  "binomial"))
}
\arguments{
\item{y}{Vector of the response value.}

\item{lambda}{Regularization parameter.}

\item{delta}{Additional regularization parameter, bounding the measurement error.}

\item{family}{"gaussian" for linear regression and "binomial" for logistic regression.}

\item{X}{Design matrix.}
}
\value{
Intercept and coefficients at the values of lambda and delta specified.
}
\description{
Generalized Matrix Uncertainty Selector
}
\examples{
# Example with linear regression
set.seed(1)
n <- 1000 # Number of samples
p <- 200 # Number of covariates
X <- matrix(rnorm(n * p), nrow = n) # True (latent) variables
W <- X + matrix(rnorm(n*p, sd = 1), nrow = n, ncol = p) # Measurement matrix (this is the one we observe)
beta <- c(seq(from = 0.1, to = 1, length.out = 5), rep(0, p-5)) # Coefficient vector
y <- X \%*\% beta + rnorm(n, sd = 1) # Response
gmus1 <- fit_gmus(W, y) # Run the MU Selector
plot(fit) # Draw an elbow plot to select delta

# Now, according to the "elbow rule", choose the final delta where the curve has an "elbow".
# In this case, the elbow is at about delta = 0.08, so we use this to compute the final estimate:
gmus2 <- fit_gmus(W, y, delta = 0.08)
plot(fit) # Plot the coefficients

}
\references{
Emmanuel Candes and Terence Tao. 2007. "The Dantzig Selector: Statistical Estimation When p Is Much Larger Than n." The Annals of Statistics 35 (6) https://projecteuclid.org/euclid.aos/1201012958
}
